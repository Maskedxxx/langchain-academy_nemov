{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e83a41b",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/deployment.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239303-lesson-8-deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20242c4-0010-4065-89f6-0e0b16c7da6e",
   "metadata": {},
   "source": [
    "# Развертывание\n",
    "\n",
    "## Обзор\n",
    "\n",
    "Мы создали агента с памятью:\n",
    "\n",
    "* `act` - позволить модели вызывать конкретные инструменты\n",
    "* `observe` - передавать вывод инструмента обратно в модель\n",
    "* `reason` - позволить модели размышлять о выводах инструмента, чтобы решить, что делать дальше (например, вызвать другой инструмент или просто ответить напрямую)\n",
    "* `persist state` - использовать контрольную точку в памяти для поддержки длительных разговоров с перерывами\n",
    "\n",
    "## Цели\n",
    "\n",
    "Теперь мы рассмотрим, как развернуть нашего агента локально в Studio и в `LangGraph Cloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f348498b-f277-4514-b163-fe5ed9afe6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph_sdk langchain_core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d0f4a7-82ee-4458-bd9a-e246ce2dc4ae",
   "metadata": {},
   "source": [
    "## Концепции\n",
    "\n",
    "Есть несколько центральных концепций, которые нужно понять —\n",
    "\n",
    "`LangGraph` —\n",
    "- Библиотека для Python и JavaScript\n",
    "- Позволяет создавать рабочие процессы агентов\n",
    "\n",
    "`LangGraph API` —\n",
    "- Упаковывает код графа\n",
    "- Предоставляет очередь задач для управления асинхронными операциями\n",
    "- Обеспечивает постоянство для поддержания состояния между взаимодействиями\n",
    "\n",
    "`LangGraph Cloud` —\n",
    "- Хостинговая служба для LangGraph API\n",
    "- Позволяет развертывать графы из репозиториев GitHub\n",
    "- Также предоставляет мониторинг и трассировку для развернутых графов\n",
    "- Доступен через уникальный URL для каждого развертывания\n",
    "\n",
    "`LangGraph Studio` —\n",
    "- Интегрированная среда разработки (IDE) для приложений LangGraph\n",
    "- Использует API как серверную часть, позволяя тестировать и исследовать графы в реальном времени\n",
    "- Может быть запущен локально или с развертыванием в облаке\n",
    "\n",
    "`LangGraph SDK` —\n",
    "- Библиотека Python для программного взаимодействия с графами LangGraph\n",
    "- Предоставляет согласованный интерфейс для работы с графами, независимо от того, обслуживаются ли они локально или в облаке\n",
    "- Позволяет создавать клиентов, получать доступ к ассистентам, управлять потоками и выполнять запуска\n",
    "\n",
    "## Тестирование локально\n",
    "\n",
    "--\n",
    "\n",
    "**⚠️ ОТКАЗ ОТ ОТВЕТСТВЕННОСТИ**\n",
    "\n",
    "*Для работы Studio требуется Mac. Если вы не используете Mac, пропустите этот шаг.*\n",
    "\n",
    "*Если вы работаете с этим ноутбуком в CoLab, пропустите этот шаг.*\n",
    "\n",
    "--\n",
    "\n",
    "Мы можем легко подключиться к графам, которые обслуживаются локально в LangGraph Studio!\n",
    "\n",
    "Мы делаем это через `url`, предоставленный в нижнем левом углу интерфейса Studio.\n",
    "\n",
    "![Screenshot 2024-08-23 at 1.17.05 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4f53080e6802cec34d_deployment%201.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa75ebd4-91fe-42c5-8122-c81e72133477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if 'google.colab' in str(get_ipython()) or platform.system() != 'Darwin':\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab or requires a Mac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b281d8-bd07-4721-922c-347838ceee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c96f353-5dc3-41c8-a3e4-6bf07ca455f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the URL of your own deployed graph\n",
    "URL = \"http://localhost:64157\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1352fa-68ad-4963-890e-c95d93570917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'created_at': '2024-12-28T07:01:53.358131+00:00',\n",
       " 'updated_at': '2024-12-28T07:01:53.358131+00:00',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'},\n",
       " 'version': 1,\n",
       " 'name': 'agent'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9c28a0-d712-496c-b191-7d620589ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы создаем поток для отслеживания состояния нашего запуска\n",
    "thread = await client.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e4177-3644-43fa-a2f1-08f73292d1a6",
   "metadata": {},
   "source": [
    "Теперь мы можем запустить нашего агента с помощью [client.runs.stream](https://langchain-ai.github.io/langgraph/concepts/low_level/#stream-and-astream) с:\n",
    "\n",
    "* `thread_id`\n",
    "* `graph_id`\n",
    "* `input`\n",
    "* `stream_mode`\n",
    "\n",
    "Мы подробно рассмотрим стриминг в следующем модуле.\n",
    "\n",
    "Пока просто примите к сведению, что мы [стримим](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/) полное значение состояния после каждого шага графа с `stream_mode=\"values\"`.\n",
    "\n",
    "Состояние захватывается в `chunk.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a4480-66b3-48bf-9158-191a7b8c1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'e63656e6-09d1-456f-9c8b-9d597d728b3b', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_droXbSErsfqREGWVixry3l4S', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 135, 'total_tokens': 153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-d8da96d3-96c1-4754-9194-a81b1ac16017-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_droXbSErsfqREGWVixry3l4S', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 135, 'output_tokens': 18, 'total_tokens': 153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'd8878adf-7e3e-4392-876c-ac9e8c6af315', 'tool_call_id': 'call_droXbSErsfqREGWVixry3l4S', 'artifact': None, 'status': 'success'}\n",
      "{'content': 'The result of multiplying 3 by 2 is 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 15, 'prompt_tokens': 160, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-a5f20e0a-e71e-498e-9e41-da85ea5165ab-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 160, 'output_tokens': 15, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agent\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa8b850-750c-4054-95e4-1c457a12ec8a",
   "metadata": {},
   "source": [
    "## Тестирование в облаке\n",
    "\n",
    "Мы можем развернуть в Cloud через LangSmith, как описано [здесь](https://langchain-ai.github.io/langgraph/cloud/quick_start/#deploy-from-github-with-langgraph-cloud).\n",
    "\n",
    "### Создайте новый репозиторий на GitHub\n",
    "\n",
    "* Перейдите в ваш аккаунт на GitHub\n",
    "* Нажмите на иконку \"+\" в правом верхнем углу и выберите `\"New repository\"`\n",
    "* Назовите ваш репозиторий (например, `langchain-academy`)\n",
    "\n",
    "### Добавьте ваш репозиторий GitHub как удаленный\n",
    "\n",
    "* Вернитесь в терминал, где вы клонировали `langchain-academy` в начале этого курса\n",
    "* Добавьте ваш только что созданный репозиторий GitHub как удаленный\n",
    "\n",
    "###\n",
    "git remote add origin https://github.com/your-username/your-repo-name.git\n",
    "###\n",
    "* Запушьте изменения\n",
    "###\n",
    "git push -u origin main\n",
    "###\n",
    "\n",
    "### Подключите LangSmith к вашему репозиторию GitHub\n",
    "\n",
    "* Перейдите на [LangSmith](hhttps://smith.langchain.com/)\n",
    "* Нажмите на вкладку `deployments` в левом меню LangSmith\n",
    "* Добавьте `+ New Deployment`\n",
    "* Затем выберите GitHub репозиторий (например, `langchain-academy`), который вы только что создали для курса\n",
    "* Укажите `LangGraph API config file` на одну из директорий `studio`\n",
    "* Например, для модуля-1 используйте: `module-1/studio/langgraph.json`\n",
    "* Установите ваши API ключи (например, можно просто скопировать из файла `module-1/studio/.env`)\n",
    "\n",
    "### Работайте с вашим развертыванием\n",
    "\n",
    "Мы можем взаимодействовать с нашим развертыванием несколькими способами:\n",
    "\n",
    "* С помощью [SDK](https://langchain-ai.github.io/langgraph/cloud/quick_start/#use-with-the-sdk), как и раньше.\n",
    "* С помощью [LangGraph Studio](https://langchain-ai.github.io/langgraph/cloud/quick_start/#interact-with-your-deployment-via-langgraph-studio).\n",
    "\n",
    "![Screenshot 2024-08-23 at 10.59.36 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fa159a09a51d601de_deployment3.png)\n",
    "\n",
    "Чтобы использовать SDK здесь, в ноутбуке, убедитесь, что `LANGSMITH_API_KEY` установлен!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646ed351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dda16c-c87f-4c03-b910-d647e83400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the URL of your deployed graph\n",
    "URL = \"https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefa37c0-92fe-4e80-9d5a-80a77b1e3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the agent\n",
    "agent = assistants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b810376e-f20f-443a-b1ca-d6793f358f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       " 'graph_id': 'agent',\n",
       " 'created_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'updated_at': '2024-08-23T17:58:02.722920+00:00',\n",
       " 'config': {},\n",
       " 'metadata': {'created_by': 'system'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32d65d84-1bcf-4af4-a7c9-55e73d6c1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Multiply 3 by 2.', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8ea04559-f7d4-4c82-89d9-c60fb0502f21', 'example': False}\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'function': {'arguments': '{\"a\":3,\"b\":2}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-b0ea5ddd-e9ba-4242-bb8c-80eb52466c76', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '1bf558e7-79ef-4f21-bb66-acafbd04677a', 'tool_call_id': 'call_EQoolxFaaSVU8HrTnCmffLk7', 'artifact': None, 'status': 'success'}\n",
      "{'content': '3 multiplied by 2 equals 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27'}, 'type': 'ai', 'name': None, 'id': 'run-ecc4b6ad-af15-4a85-a76c-de2ed0ed8ed9', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# We create a thread for tracking the state of our run\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Input\n",
    "input = {\"messages\": [HumanMessage(content=\"Multiply 3 by 2.\")]}\n",
    "\n",
    "# Stream\n",
    "async for chunk in client.runs.stream(\n",
    "        thread['thread_id'],\n",
    "        \"agent\",\n",
    "        input=input,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "    if chunk.data and chunk.event != \"metadata\":\n",
    "        print(chunk.data['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cb34d-c3b8-4446-a7e3-5fe938abf99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
